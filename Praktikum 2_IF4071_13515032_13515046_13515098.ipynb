{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktikum 2 IF 4071\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi Oleh Kelompok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class NeuralNet:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, nodes_n_in_hidden_layers, learning_rate, momentum):\n",
    "        nodes_n_in_hidden_layers.append(1) # satu node buat output\n",
    "        self.nodes_n_in_hidden_layers = nodes_n_in_hidden_layers\n",
    "        self.inputs = [] #data input\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.outputs = [] # output dari setiap node pada satu iterasi\n",
    "        self.weights = [] # weight dari setiap edge pada satu iterasi\n",
    "        self.biases = [] # bias dari setiap node pada satu iterasi\n",
    "        self.weight_biases = []\n",
    "        self.local_gradients = [] # local gradient dari setiap node pada satu iterasi\n",
    "        self.delta_weights = [] # delta weight dari setiap edge pada satu iterasi\n",
    "        self.delta_biases = [] # delta bias dari setiap node pada satu iterasi\n",
    "        self.layer_nodes = [] # node-node pada layer-layer\n",
    "        self.v = [] # v pada setiap node\n",
    "        self.targets = [] # target dari data input\n",
    "        self.test_outputs = [] # hasil predict data test\n",
    "        self.test_labels = [] # label hasil predict data test\n",
    "        \n",
    "    # Feed Forward\n",
    "    def feed_forward(self, datum_idx):\n",
    "        for i in range (1, len(self.layer_nodes)):\n",
    "            for j in range (0, len(self.layer_nodes[i])):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                weights = []\n",
    "                weights.append(self.biases[current_node])\n",
    "                inputs = []\n",
    "                inputs.append(1)\n",
    "                for k in range(0, len(self.layer_nodes[i-1])):\n",
    "                    if (self.weights[self.layer_nodes[i-1][k]][current_node] != None):\n",
    "                            weights.append(self.weights[self.layer_nodes[i-1][k]][current_node])\n",
    "                    \n",
    "                    if (i==1):\n",
    "                        inputs.append(self.inputs[datum_idx][self.layer_nodes[i-1][k]])\n",
    "                    else:\n",
    "                        inputs.append(self.outputs[self.layer_nodes[i-1][k]])\n",
    "                v = np.dot(inputs, weights)\n",
    "                self.v[current_node] = v\n",
    "                self.outputs[current_node] = sigmoid(v)\n",
    "                \n",
    "    # Back Propagation\n",
    "    def back_propagation(self, datum_idx):\n",
    "        for i in range(len(self.layer_nodes)-1, 0, -1):\n",
    "            for j in range(len(self.layer_nodes[i])-1, -1, -1):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                if (i == len(self.layer_nodes)-1):\n",
    "                    v = self.v[current_node]\n",
    "                    sig_v = sigmoid(v)\n",
    "                    self.local_gradients[current_node] = self.local_gradients[current_node] + (sig_v * (1 - sig_v) * (self.targets[datum_idx] - self.outputs[current_node]))\n",
    "                else:\n",
    "                    v = self.v[current_node]\n",
    "                    sig_v = sigmoid(v)\n",
    "                    weight_delta = 1\n",
    "                    for k in range(0, len(self.layer_nodes[i+1])):\n",
    "                        weight_delta = weight_delta * self.local_gradients[self.layer_nodes[i+1][k]] * self.weights[current_node][self.layer_nodes[i+1][k]]\n",
    "                    self.local_gradients[current_node] = self.local_gradients[current_node] + (sig_v * (1 - sig_v) * weight_delta)            \n",
    "                \n",
    "    # Update Weight\n",
    "    def update_weight(self):\n",
    "        for i in range(0, len(self.layer_nodes)-1):\n",
    "            for j in range(0, len(self.layer_nodes[i])):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                for k in range(0, len(self.layer_nodes[i+1])):\n",
    "                    current_next_node = self.layer_nodes[i+1][k]\n",
    "                    self.delta_weights[current_node][current_next_node] = self.momentum * self.delta_weights[current_node][current_next_node] + self.learning_rate * self.local_gradients[current_next_node] * self.outputs[current_next_node]\n",
    "                    self.weights[current_node][current_next_node] += self.delta_weights[current_node][current_next_node]\n",
    "        for i in range(1, len(self.biases)):\n",
    "            new_bias = self.biases[i] + self.momentum  * self.delta_biases[i] + self.learning_rate * self.local_gradients[i]\n",
    "            self.delta_biases[i] = new_bias - self.biases[i]\n",
    "            self.biases[i] = new_bias\n",
    "            \n",
    "    # Fit\n",
    "    def fit(self, X, Y, batch_size, max_iter, threshold): # data = array of arrays\n",
    "        #data[0] ke n merupakan label\n",
    "        #nodes_n_in_hidden_layers[0] merupakan jumlah input\n",
    "        self.nodes_n_in_hidden_layers.insert(0, len(X[0])) \n",
    "        \n",
    "        self.targets = Y\n",
    "        self.inputs = X\n",
    "        \n",
    "        n_nodes = 0\n",
    "        init_weight = 1 # Weights diinisalisasi 0\n",
    "        \n",
    "        # Inisialisasi output, bias, local gradient, v, dan delta bias di setiap node pada layer\n",
    "        for i in range(0, len(self.nodes_n_in_hidden_layers)):\n",
    "            l_nodes = []\n",
    "            for j in range(0, self.nodes_n_in_hidden_layers[i]):\n",
    "                self.outputs.append(0)\n",
    "                self.v.append(0)\n",
    "                self.biases.append(0) #asumsi x bias = 1\n",
    "                self.local_gradients.append(0)\n",
    "                self.delta_biases.append(0)\n",
    "                l_nodes.append(n_nodes)\n",
    "                n_nodes += 1\n",
    "            self.layer_nodes.append(l_nodes)\n",
    "        \n",
    "        for i in range(0, n_nodes):\n",
    "            self.weights.append([])\n",
    "            self.delta_weights.append([])\n",
    "            for j in range(0, n_nodes):\n",
    "                self.weights[i].append(None)\n",
    "                self.delta_weights[i].append(None)\n",
    "            \n",
    "        current_node = 0\n",
    "        for i in range(0, len(self.nodes_n_in_hidden_layers)-1):\n",
    "            if (i < len(self.nodes_n_in_hidden_layers)-1):\n",
    "                next_layer_first_node = current_node + self.nodes_n_in_hidden_layers[i]\n",
    "                for j in range(0, self.nodes_n_in_hidden_layers[i]):\n",
    "                    for k in range(0, self.nodes_n_in_hidden_layers[i+1]):\n",
    "                        self.weights[current_node][k+next_layer_first_node] = random.uniform(-0.5,0.5)\n",
    "                        self.delta_weights[current_node][k+next_layer_first_node] = 0\n",
    "                    current_node += 1\n",
    "        \n",
    "        n_batch = math.ceil(len(Y)/batch_size)\n",
    "        \n",
    "        n_iter = 0\n",
    "        error = 100\n",
    "        while (n_iter < max_iter and error > threshold):\n",
    "            datum_idx = 0\n",
    "            for i in range(0, n_batch):\n",
    "                # Mengembalikan local_gradient menjadi 0\n",
    "                for i in range(0, n_nodes):\n",
    "                    self.local_gradients[i] = 0\n",
    "                    \n",
    "                j = 0\n",
    "                accum_error = 0\n",
    "                num_datum = 0\n",
    "                while (j < batch_size):\n",
    "                    if (datum_idx < len(Y)):\n",
    "                        self.feed_forward(datum_idx)\n",
    "                        accum_error = accum_error + (0.5 * ((self.targets[datum_idx] - self.outputs[-1])**2))\n",
    "                        num_datum = num_datum + 1\n",
    "                        self.back_propagation(datum_idx)\n",
    "                        datum_idx += 1\n",
    "                        j += 1\n",
    "                    else:\n",
    "                        j = batch_size + 1\n",
    "                error = accum_error / num_datum\n",
    "                if (error < threshold):\n",
    "                    break\n",
    "                self.update_weight()\n",
    "            \n",
    "            n_iter += 1\n",
    "        \n",
    "    # Predict\n",
    "    def predict(self, data_test):\n",
    "        self.inputs = data_test\n",
    "        self.test_outputs = []\n",
    "        for i in range (0, len(data_test)):\n",
    "            self.feed_forward(i)\n",
    "            self.test_outputs.append(self.outputs[-1])\n",
    "        return self.test_outputs\n",
    "    \n",
    "    def predict_label(self):\n",
    "        for i in range (0, len(self.test_outputs)):\n",
    "            threshold = 0\n",
    "            for j in range(0, 15):\n",
    "                if (self.test_outputs[i] >= threshold and self.test_outputs[i] < (threshold + (1/15))):\n",
    "                    self.test_outputs[i] = j * (1/15)\n",
    "                threshold = threshold + (1/15)\n",
    "                \n",
    "        return self.test_labels\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_label(data):\n",
    "    decoded_data = []\n",
    "    for i in range(0, len(data)):\n",
    "        threshold = 0\n",
    "        for j in range(0, 16):\n",
    "            if (data[i] >= threshold and data[i] < (threshold + (1/15))):\n",
    "                decoded_data.append(j)\n",
    "            threshold = threshold + (1/15)\n",
    "    return decoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi dengan Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "class KerasNeuralNet:\n",
    "    \n",
    "    # Construction\n",
    "    def __init__(self, nodes_n_in_hidden_layers, learning_rate, momentum):\n",
    "        nodes_n_in_hidden_layers.append(1) # satu node buat output\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(output_dim=nodes_n_in_hidden_layers[0], input_dim=96, activation=\"sigmoid\"))\n",
    "        for i in range(1, len(nodes_n_in_hidden_layers)):\n",
    "            self.model.add(Dense(output_dim=nodes_n_in_hidden_layers[i], input_dim=nodes_n_in_hidden_layers[i-1], activation='sigmoid'))\n",
    "        sgd = optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=False)\n",
    "        self.model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "        \n",
    "    def fit(self, X, Y, batch_size, max_iter):\n",
    "        self.model.fit(X, Y, batch_size=batch_size, epochs=max_iter)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membaca Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46666667]\n",
      " [ 0.66666667]\n",
      " [ 0.4       ]\n",
      " ..., \n",
      " [ 0.53333333]\n",
      " [ 0.6       ]\n",
      " [ 0.26666667]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv('data_training_praktikum.csv')\n",
    "dataframe = dataframe.drop(['no_textstructure_formulaic','them_formulaic','affect',\\\n",
    "                       'argumentation','better_solution','change','comparison','continue','contrast','interest','need',\\\n",
    "                       'presentation','problem','research','solution','textstructure','use','copula','aim_ref_agent',\\\n",
    "                        'gap_agent','general_agent','ref_agent','ref_us_agent','textstructure_agent','them_agent',\\\n",
    "                       'them_pronoun_agent','us_agent'], axis=1)\n",
    "\n",
    "# Transform outlook, temperature, humidity, and windy to numerical values\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "data_X = dataframe.values[:,0:32]\n",
    "data_Y = dataframe.values[:,32]\n",
    "data_X = enc.fit_transform(data_X).toarray()\n",
    "dataframe\n",
    "#reScale\n",
    "le = LabelEncoder()\n",
    "data_Y = le.fit_transform(data_Y)\n",
    "\n",
    "matrix_Y = []\n",
    "for i in range(0, len(data_Y)):\n",
    "    matrix_Y.append([data_Y[i]])\n",
    "data_Y = scaler.fit_transform(matrix_Y)\n",
    "print(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting dengan Hasil Implementasi Kelompok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best fit f1 0.303968253968\n",
      "0.253374622836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# nn = NeuralNet([6], 0.25, 0.0001)\n",
    "# nn.fit(rescaledX, Y, 1, 5, 0.01)\n",
    "# nn.predict(rescaledX)\n",
    "# print(nn.test_outputs)\n",
    "# print(nn.predict_label())\n",
    "best_model = NeuralNet([0], 0, 0)\n",
    "best_f1 = 0\n",
    "for train_index, test_index in kf.split(data_X):\n",
    "        X_train, X_test = data_X[train_index], data_X[test_index]\n",
    "        Y_train, Y_test = data_Y[train_index], data_Y[test_index]\n",
    "        nn = NeuralNet([6], 0.25, 0.0001)\n",
    "        nn.fit(X_train, Y_train, 1, 5, 0.01)\n",
    "        nn.predict(X_test)\n",
    "        decoded_output = decode_label(nn.test_outputs)\n",
    "        decoded_data = decode_label(Y_test)\n",
    "        f1 = f1_score(decoded_data, decoded_output, average='micro')\n",
    "        if (f1 >= best_f1):\n",
    "            best_model = nn\n",
    "            best_f1 = f1\n",
    "print(\"best fit f1\", best_f1)\n",
    "best_model.predict(data_X)\n",
    "print(f1_score(decode_label(data_Y), decode_label(best_model.test_outputs), average='micro'))\n",
    "##print(nn.test_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting dengan Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=96, activation=\"sigmoid\", units=4)`\n",
      "  del sys.path[0]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=4, activation=\"sigmoid\", units=4)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=4, activation=\"sigmoid\", units=2)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=2, activation=\"sigmoid\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 23s 2ms/step - loss: 0.0601 - acc: 0.0815\n",
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 21s 2ms/step - loss: 0.0577 - acc: 0.0796\n",
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 24s 2ms/step - loss: 0.0508 - acc: 0.0935\n",
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 22s 2ms/step - loss: 0.0493 - acc: 0.0964\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 22s 2ms/step - loss: 0.0491 - acc: 0.0962\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 21s 2ms/step - loss: 0.0480 - acc: 0.0910: 0s - loss: 0.0480 - a\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 25s 2ms/step - loss: 0.0458 - acc: 0.0845\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 22s 2ms/step - loss: 0.0462 - acc: 0.0798\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 23s 2ms/step - loss: 0.0457 - acc: 0.0805\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 28s 2ms/step - loss: 0.0436 - acc: 0.0878\n",
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 34s 3ms/step - loss: 0.0606 - acc: 0.0816\n",
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 24s 2ms/step - loss: 0.0602 - acc: 0.0787\n",
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 27s 2ms/step - loss: 0.0576 - acc: 0.0806\n",
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 31s 3ms/step - loss: 0.0513 - acc: 0.0942\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 21s 2ms/step - loss: 0.0501 - acc: 0.0962\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 21s 2ms/step - loss: 0.0489 - acc: 0.0914\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 27s 2ms/step - loss: 0.0465 - acc: 0.0850\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 23s 2ms/step - loss: 0.0469 - acc: 0.0796\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 24s 2ms/step - loss: 0.0464 - acc: 0.0804\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 27s 2ms/step - loss: 0.0442 - acc: 0.0885\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.2, 0.3]\n",
    "best_acc = 0\n",
    "for lr in lrs:\n",
    "    knn = KerasNeuralNet([4,4,2], lr, 0.0001)    \n",
    "    for train_index, test_index in kf.split(data_X):\n",
    "        data_X_train, data_X_test = data_X[train_index], data_X[test_index]\n",
    "        data_Y_train, data_Y_test = data_Y[train_index], data_Y[test_index]\n",
    "        array_Y = []\n",
    "        for i in range(0, len(data_Y)):\n",
    "            array_Y.append(data_Y[i][0])\n",
    "        data_Y = array_Y\n",
    "        knn.fit(data_X_train, data_Y_train, 1, 1)\n",
    "        matrix_Y = []\n",
    "        for i in range(0, len(data_Y)):\n",
    "            matrix_Y.append([data_Y[i]])\n",
    "        data_Y = np.asarray(matrix_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=96, activation=\"sigmoid\", units=4)`\n",
      "  del sys.path[0]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=4, activation=\"sigmoid\", units=4)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=4, activation=\"sigmoid\", units=2)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=2, activation=\"sigmoid\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 30s 3ms/step - loss: 0.0606 - acc: 0.0812\n",
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 25s 2ms/step - loss: 0.0548 - acc: 0.0859\n",
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 22s 2ms/step - loss: 0.0504 - acc: 0.0926\n",
      "Epoch 1/1\n",
      "11334/11334 [==============================] - 23s 2ms/step - loss: 0.0494 - acc: 0.0959\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 21s 2ms/step - loss: 0.0492 - acc: 0.0952\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 21s 2ms/step - loss: 0.0481 - acc: 0.0910\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 20s 2ms/step - loss: 0.0458 - acc: 0.0850\n",
      "Epoch 1/1\n",
      "11335/11335 [==============================] - 24s 2ms/step - loss: 0.0461 - acc: 0.0797\n",
      "Epoch 1/1\n",
      " 8042/11335 [====================>.........] - ETA: 8s - loss: 0.0457 - acc: 0.0814"
     ]
    }
   ],
   "source": [
    "knn = KerasNeuralNet([4,4,2], 0.3, 0.0001)   \n",
    "batch_sz = [1,11335]\n",
    "for sz in batch_sz:\n",
    "    for train_index, test_index in kf.split(data_X):\n",
    "        data_X_train, data_X_test = data_X[train_index], data_X[test_index]\n",
    "        data_Y_train, data_Y_test = data_Y[train_index], data_Y[test_index]\n",
    "        array_Y = []\n",
    "        for i in range(0, len(data_Y)):\n",
    "            array_Y.append(data_Y[i][0])\n",
    "        data_Y = array_Y\n",
    "        knn.fit(data_X_train, data_Y_train, sz, 1)\n",
    "        matrix_Y = []\n",
    "        for i in range(0, len(data_Y)):\n",
    "            matrix_Y.append([data_Y[i]])\n",
    "        data_Y = np.asarray(matrix_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hasil Analisis Data dan Penanganan\n",
    "Pada data train yang diberikan, terdapat banyak atribut yang bernilai hanya 1 nilai (yaitu 0 saja). Terhadap atribut dengan 1 nilai tersebut, kami mengeleminasi atribut tersebut dari data input yang digunakan untuk pembelajaran. Selain itu, kami juga memisahkan antara data train yang merupakan label kelas dengan data train yang bukan label kelas. Data train yang bukan label kelas, kami terapkan one hot encoding dan pada data train label kelas kami lakukan label encoder dan hasil kami rescale antara nilai 0 sampai dengan 1.\n",
    "\n",
    "### 2. Skenario Eksperimen\n",
    "Berikut merupakan faktor, parameter serta skenario pembagian data yang digunakan dalam eksperimen praktikum :\n",
    "#### 1. Faktor\n",
    "- Jumlah Layer\n",
    "- Jumlah Node pada setiap Layer\n",
    "- Fungsi Aktivasi\n",
    "- Optimizer\n",
    "\n",
    "#### 2. Parameter\n",
    "- Learning rate\n",
    "- Momentum\n",
    "- Batch size\n",
    "- Max Epoch\n",
    "\n",
    "#### 3. Pembagian data dengan 10-fold\n",
    "\t\t\n",
    "### 3. Hasil Eksperimen\n",
    "#### 1. Hasil dan Konfigurasi\n",
    "##### Implementasi MLP Tugas Besar II\n",
    "##### Implementasi MLP Keras\n",
    "Pada Keras, learning_rate = 0.3 lebih baik daripada learning_rate = 0.2 untuk kasus ini.\n",
    "Perbandingan Hasil\n",
    "\n",
    "### 4. Analisis Hasil Eksperimen\n",
    "#### Kekonsistenan Model\n",
    "#### Perbandingan Sifat General antar Model\n",
    "#### Penjelasan Perbedaan Kinerja antar Model\n",
    "\n",
    "### 5. Kesimpulan\n",
    "### 6. Klasifikasi terhadap Data Test\n",
    "### 7. Saran dan Rekomendasi\n",
    "Pelaksanaan praktikum bisa dilakukan secara remote karena waktu yang diperlukan untuk menjalan satu eksperimen cukup lama, sehingga untuk melakukan eksperimen dengan parameter yang lebih bervariatif tidak dapat dilakukan dengan optimal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Persentase Tugas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Helena Suzane Graciella (13515032) 33%\n",
    "   \n",
    "2. Lathifah Nurrahmah (13515046) 33%\n",
    "    \n",
    "3. Aya Aurora Rimbamorani (13515098) 33%\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
