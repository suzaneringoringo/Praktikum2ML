{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktikum 2 IF 4071\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi Oleh Kelompok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class NeuralNet:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, nodes_n_in_hidden_layers, learning_rate, momentum):\n",
    "        nodes_n_in_hidden_layers.append(1) # satu node buat output\n",
    "        self.nodes_n_in_hidden_layers = nodes_n_in_hidden_layers\n",
    "        self.inputs = [] #data input\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.outputs = [] # output dari setiap node pada satu iterasi\n",
    "        self.weights = [] # weight dari setiap edge pada satu iterasi\n",
    "        self.biases = [] # bias dari setiap node pada satu iterasi\n",
    "        self.weight_biases = []\n",
    "        self.local_gradients = [] # local gradient dari setiap node pada satu iterasi\n",
    "        self.delta_weights = [] # delta weight dari setiap edge pada satu iterasi\n",
    "        self.delta_biases = [] # delta bias dari setiap node pada satu iterasi\n",
    "        self.layer_nodes = [] # node-node pada layer-layer\n",
    "        self.v = [] # v pada setiap node\n",
    "        self.targets = [] # target dari data input\n",
    "        self.test_outputs = [] # hasil predict data test\n",
    "        self.test_labels = [] # label hasil predict data test\n",
    "        \n",
    "    # Feed Forward\n",
    "    def feed_forward(self, datum_idx):\n",
    "        for i in range (1, len(self.layer_nodes)):\n",
    "            for j in range (0, len(self.layer_nodes[i])):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                weights = []\n",
    "                weights.append(self.biases[current_node])\n",
    "                inputs = []\n",
    "                inputs.append(1)\n",
    "                for k in range(0, len(self.layer_nodes[i-1])):\n",
    "                    if (self.weights[self.layer_nodes[i-1][k]][current_node] != None):\n",
    "                            weights.append(self.weights[self.layer_nodes[i-1][k]][current_node])\n",
    "                    \n",
    "                    if (i==1):\n",
    "                        inputs.append(self.inputs[datum_idx][self.layer_nodes[i-1][k]])\n",
    "                    else:\n",
    "                        inputs.append(self.outputs[self.layer_nodes[i-1][k]])\n",
    "                v = np.dot(inputs, weights)\n",
    "                self.v[current_node] = v\n",
    "                self.outputs[current_node] = sigmoid(v)\n",
    "                \n",
    "    # Back Propagation\n",
    "    def back_propagation(self, datum_idx):\n",
    "        for i in range(len(self.layer_nodes)-1, 0, -1):\n",
    "            for j in range(len(self.layer_nodes[i])-1, -1, -1):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                if (i == len(self.layer_nodes)-1):\n",
    "                    v = self.v[current_node]\n",
    "                    sig_v = sigmoid(v)\n",
    "                    self.local_gradients[current_node] = self.local_gradients[current_node] + (sig_v * (1 - sig_v) * (self.targets[datum_idx] - self.outputs[current_node]))\n",
    "                else:\n",
    "                    v = self.v[current_node]\n",
    "                    sig_v = sigmoid(v)\n",
    "                    weight_delta = 1\n",
    "                    for k in range(0, len(self.layer_nodes[i+1])):\n",
    "                        weight_delta = weight_delta * self.local_gradients[self.layer_nodes[i+1][k]] * self.weights[current_node][self.layer_nodes[i+1][k]]\n",
    "                    self.local_gradients[current_node] = self.local_gradients[current_node] + (sig_v * (1 - sig_v) * weight_delta)            \n",
    "                \n",
    "    # Update Weight\n",
    "    def update_weight(self):\n",
    "        for i in range(0, len(self.layer_nodes)-1):\n",
    "            for j in range(0, len(self.layer_nodes[i])):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                for k in range(0, len(self.layer_nodes[i+1])):\n",
    "                    current_next_node = self.layer_nodes[i+1][k]\n",
    "                    self.delta_weights[current_node][current_next_node] = self.momentum * self.delta_weights[current_node][current_next_node] + self.learning_rate * self.local_gradients[current_next_node] * self.outputs[current_next_node]\n",
    "                    self.weights[current_node][current_next_node] += self.delta_weights[current_node][current_next_node]\n",
    "        for i in range(1, len(self.biases)):\n",
    "            new_bias = self.biases[i] + self.momentum  * self.delta_biases[i] + self.learning_rate * self.local_gradients[i]\n",
    "            self.delta_biases[i] = new_bias - self.biases[i]\n",
    "            self.biases[i] = new_bias\n",
    "            \n",
    "    # Fit\n",
    "    def fit(self, X, Y, batch_size, max_iter, threshold): # data = array of arrays\n",
    "        #data[0] ke n merupakan label\n",
    "        #nodes_n_in_hidden_layers[0] merupakan jumlah input\n",
    "        self.nodes_n_in_hidden_layers.insert(0, len(X[0])) \n",
    "        \n",
    "        self.targets = Y\n",
    "        self.inputs = X\n",
    "        \n",
    "        n_nodes = 0\n",
    "        init_weight = 1 # Weights diinisalisasi 0\n",
    "        \n",
    "        # Inisialisasi output, bias, local gradient, v, dan delta bias di setiap node pada layer\n",
    "        for i in range(0, len(self.nodes_n_in_hidden_layers)):\n",
    "            l_nodes = []\n",
    "            for j in range(0, self.nodes_n_in_hidden_layers[i]):\n",
    "                self.outputs.append(0)\n",
    "                self.v.append(0)\n",
    "                self.biases.append(0) #asumsi x bias = 1\n",
    "                self.local_gradients.append(0)\n",
    "                self.delta_biases.append(0)\n",
    "                l_nodes.append(n_nodes)\n",
    "                n_nodes += 1\n",
    "            self.layer_nodes.append(l_nodes)\n",
    "        \n",
    "        for i in range(0, n_nodes):\n",
    "            self.weights.append([])\n",
    "            self.delta_weights.append([])\n",
    "            for j in range(0, n_nodes):\n",
    "                self.weights[i].append(None)\n",
    "                self.delta_weights[i].append(None)\n",
    "            \n",
    "        current_node = 0\n",
    "        for i in range(0, len(self.nodes_n_in_hidden_layers)-1):\n",
    "            if (i < len(self.nodes_n_in_hidden_layers)-1):\n",
    "                next_layer_first_node = current_node + self.nodes_n_in_hidden_layers[i]\n",
    "                for j in range(0, self.nodes_n_in_hidden_layers[i]):\n",
    "                    for k in range(0, self.nodes_n_in_hidden_layers[i+1]):\n",
    "                        self.weights[current_node][k+next_layer_first_node] = random.uniform(-0.5,0.5)\n",
    "                        self.delta_weights[current_node][k+next_layer_first_node] = 0\n",
    "                    current_node += 1\n",
    "        \n",
    "        n_batch = math.ceil(len(Y)/batch_size)\n",
    "        \n",
    "        n_iter = 0\n",
    "        error = 100\n",
    "        while (n_iter < max_iter and error > threshold):\n",
    "            datum_idx = 0\n",
    "            for i in range(0, n_batch):\n",
    "                # Mengembalikan local_gradient menjadi 0\n",
    "                for i in range(0, n_nodes):\n",
    "                    self.local_gradients[i] = 0\n",
    "                    \n",
    "                j = 0\n",
    "                accum_error = 0\n",
    "                num_datum = 0\n",
    "                while (j < batch_size):\n",
    "                    if (datum_idx < len(Y)):\n",
    "                        self.feed_forward(datum_idx)\n",
    "                        accum_error = accum_error + (0.5 * ((self.targets[datum_idx] - self.outputs[-1])**2))\n",
    "                        num_datum = num_datum + 1\n",
    "                        self.back_propagation(datum_idx)\n",
    "                        datum_idx += 1\n",
    "                        j += 1\n",
    "                    else:\n",
    "                        j = batch_size + 1\n",
    "                error = accum_error / num_datum\n",
    "                if (error < threshold):\n",
    "                    break\n",
    "                self.update_weight()\n",
    "            \n",
    "            n_iter += 1\n",
    "        \n",
    "    # Predict\n",
    "    def predict(self, data_test):\n",
    "        self.inputs = data_test\n",
    "        self.test_outputs = []\n",
    "        for i in range (0, len(data_test)):\n",
    "            self.feed_forward(i)\n",
    "            self.test_outputs.append(self.outputs[-1])\n",
    "        return self.test_outputs\n",
    "    \n",
    "    def predict_label(self):\n",
    "        for i in range (0, len(self.test_outputs)):\n",
    "            threshold = 0\n",
    "            for j in range(0, 15):\n",
    "                if (self.test_outputs[i] >= threshold and self.test_outputs[i] < (threshold + (1/15))):\n",
    "                    self.test_outputs[i] = j * (1/15)\n",
    "                threshold = threshold + (1/15)\n",
    "                \n",
    "        return self.test_labels\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_label(data):\n",
    "    decoded_data = []\n",
    "    for i in range(0, len(data)):\n",
    "        threshold = 0\n",
    "        for j in range(0, 16):\n",
    "            if (data[i] >= threshold and data[i] < (threshold + (1/15))):\n",
    "                decoded_data.append(j)\n",
    "            threshold = threshold + (1/15)\n",
    "    return decoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi dengan Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "class KerasNeuralNet:\n",
    "    \n",
    "    # Construction\n",
    "    def __init__(self, nodes_n_in_hidden_layers, learning_rate, momentum):\n",
    "        nodes_n_in_hidden_layers.append(1) # satu node buat output\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(output_dim=nodes_n_in_hidden_layers[0], input_dim=92, activation=\"sigmoid\"))\n",
    "        for i in range(1, len(nodes_n_in_hidden_layers)):\n",
    "            self.model.add(Dense(output_dim=nodes_n_in_hidden_layers[i], input_dim=nodes_n_in_hidden_layers[i-1], activation='sigmoid'))\n",
    "        sgd = optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=False)\n",
    "        self.model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "        \n",
    "    def fit(self, X, Y, batch_size, max_iter):\n",
    "        self.model.fit(X, Y, batch_size=batch_size, epochs=max_iter)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membaca Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46666667]\n",
      " [ 0.66666667]\n",
      " [ 0.4       ]\n",
      " ..., \n",
      " [ 0.53333333]\n",
      " [ 0.6       ]\n",
      " [ 0.26666667]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv('data_training_praktikum.csv')\n",
    "dataframe = dataframe.drop(['gap_formulaic', 'no_textstructure_formulaic','them_formulaic','us_previous_formulaic','affect',\\\n",
    "                       'argumentation','better_solution','change','comparison','continue','contrast','interest','need',\\\n",
    "                       'presentation','problem','research','solution','textstructure','use','copula','aim_ref_agent',\\\n",
    "                        'gap_agent','general_agent','ref_agent','ref_us_agent','textstructure_agent','them_agent',\\\n",
    "                       'them_pronoun_agent','us_agent'], axis=1)\n",
    "\n",
    "# Transform outlook, temperature, humidity, and windy to numerical values\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "data_X = dataframe.values[:,0:30]\n",
    "data_Y = dataframe.values[:,30]\n",
    "data_X = enc.fit_transform(data_X).toarray()\n",
    "dataframe\n",
    "#reScale\n",
    "le = LabelEncoder()\n",
    "data_Y = le.fit_transform(data_Y)\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "matrix_Y = []\n",
    "for i in range(0, len(data_Y)):\n",
    "    matrix_Y.append([data_Y[i]])\n",
    "data_Y = scaler.fit_transform(matrix_Y)\n",
    "print(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting dengan Hasil Implementasi Kelompok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best fit f1 0.303968253968\n",
      "0.253374622836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# nn = NeuralNet([6], 0.25, 0.0001)\n",
    "# nn.fit(rescaledX, Y, 1, 5, 0.01)\n",
    "# nn.predict(rescaledX)\n",
    "# print(nn.test_outputs)\n",
    "# print(nn.predict_label())\n",
    "best_model = NeuralNet([0], 0, 0)\n",
    "best_f1 = 0\n",
    "for train_index, test_index in kf.split(data_X):\n",
    "        X_train, X_test = data_X[train_index], data_X[test_index]\n",
    "        Y_train, Y_test = data_Y[train_index], data_Y[test_index]\n",
    "        nn = NeuralNet([6], 0.25, 0.0001)\n",
    "        nn.fit(X_train, Y_train, 1, 5, 0.01)\n",
    "        nn.predict(X_test)\n",
    "        decoded_output = decode_label(nn.test_outputs)\n",
    "        decoded_data = decode_label(Y_test)\n",
    "        f1 = f1_score(decoded_data, decoded_output, average='micro')\n",
    "        if (f1 >= best_f1):\n",
    "            best_model = nn\n",
    "            best_f1 = f1\n",
    "print(\"best fit f1\", best_f1)\n",
    "best_model.predict(data_X)\n",
    "print(f1_score(decode_label(data_Y), decode_label(best_model.test_outputs), average='micro'))\n",
    "##print(nn.test_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting dengan Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=92, activation=\"sigmoid\", units=6)`\n",
      "  del sys.path[0]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=6, activation=\"sigmoid\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-8c829cf57c6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0marray_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdata_Y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_Y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_Y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "knn = KerasNeuralNet([6], 0.25, 0.0001)\n",
    "for train_index, test_index in kf.split(data_X):\n",
    "    data_X_train, data_X_test = data_X[train_index], data_X[test_index]\n",
    "    array_Y = []\n",
    "    for i in range(0, len(data_Y)):\n",
    "        array_Y.append([data_Y[i]])\n",
    "    data_Y = array_Y\n",
    "    data_Y_train, data_Y_test = data_Y[train_index], data_Y[test_index]\n",
    "\n",
    "    knn.fit(data_X_train, data_Y_train, 1, 5)\n",
    "\n",
    "# knn = KerasNeuralNet([6], 0.25, 0.0001)\n",
    "\n",
    "# # Train model\n",
    "# knn.fit(rescaledX, Y, 1, 5)\n",
    "\n",
    "# # Predict\n",
    "# labels = knn.predict(rescaledX)\n",
    "# print(labels)\n",
    "# for i in range(0, len(labels)):\n",
    "#     if (labels[i] >= 0.5):\n",
    "#         labels[i] = 1\n",
    "#     else:\n",
    "#         labels[i] = 0\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perbandingan Hasil Implementasi Kelompok dengan Keras\n",
    "Meskipun label yang dihasilkan sama persis, nilai sebenarnya dari feed_forward berbeda. Hal ini dapat terjadi karena nilai weights pada saat inisialisasi adalah random sehingga kemungkinan besar berbeda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pembagian Tugas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Helena Suzane Graciella (13515032)\n",
    "   \n",
    "2. Lathifah Nurrahmah (13515046)\n",
    "    \n",
    "3. Aya Aurora Rimbamorani (13515098)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
