{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Praktikum IF4071</h1>\n",
    "<p>13515032 Helena Suzane Graciella</p>\n",
    "<p>13515034 Roselina Pradjanata</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('CensusIncome/CencusIncome.data.txt', sep=',\\s', header=None, na_values=[\"?\"], engine='python')\n",
    "raw_df.dropna(inplace=True)\n",
    "\n",
    "raw_test_df = pd.read_csv('CensusIncome/CencusIncome.test.txt', sep=',\\s', header=None, na_values=[\"?\"], engine='python', skiprows=1)\n",
    "raw_test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income_df = pd.DataFrame()\n",
    "income_test_df = pd.DataFrame()\n",
    "le = {}\n",
    "for feature in raw_df:\n",
    "    le[feature] = LabelEncoder()\n",
    "    income_df[feature] = le[feature].fit_transform(raw_df[feature])\n",
    "    income_test_df[feature] = le[feature].fit_transform(raw_test_df[feature])\n",
    "income_X = income_df.iloc[:, 0:14]\n",
    "income_Y = income_df.iloc[:, 14]\n",
    "income_test_X = income_test_df.iloc[:, 0:14]\n",
    "income_test_Y = income_test_df.iloc[:, 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Setelah dianalisis, dataset mempunyai kolom bertipe string dan bertipe integer. Fungsi clustering pada sklearn tidak dapat memproses data bertipe string, sehingga data bertipe string harus diubah ke integer. Dataset tersebut juga mempunyai instance yang kolomnya memiliki missing value. Nilai tersebut dapat ditangani dengan beberapa cara, antara lain dengan menghilangkan instance yang memiliki missing value, atau dengan mengubah missing value tersebut dengan nilai lain.\n",
    "Penanganan data yang dilakukan pertama-tama adalah dengan mengubah label data bertipe string ke bertipe integer dengan label encoder. Selanjutnya, dilakukan penanganan instance yang kolomnya mengandung missing value (?) dengan menghilangkan instance tersebut.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income_kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def purity(clustered, y_true):\n",
    "    class_0 = []\n",
    "    class_1 = []\n",
    "    \n",
    "    for i in range(0, len(y_true)):\n",
    "        if (clustered[i] == 0):\n",
    "            class_0.append(y_true[i])\n",
    "        else:\n",
    "            class_1.append(y_true[i])\n",
    "    \n",
    "    class_0_mode = max(set(class_0), key=class_0.count)\n",
    "    class_1_mode = max(set(class_1), key=class_1.count)\n",
    "    \n",
    "    n_mode_0 = 0\n",
    "    for instance in class_0:\n",
    "        if (instance == class_0_mode):\n",
    "            n_mode_0 += 1\n",
    "            \n",
    "    n_mode_1 = 0\n",
    "    for instance in class_1:\n",
    "        if (instance == class_1_mode):\n",
    "            n_mode_1 += 1\n",
    "            \n",
    "    purity_total = (n_mode_0 + n_mode_1)/len(clustered)\n",
    "    return purity_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>K-Means</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "Purity = 0.7521827224166513\n",
      "KMeans(algorithm='full', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "Purity = 0.7521827224166513\n",
      "KMeans(algorithm='elkan', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "Purity = 0.7521827224166513\n",
      "KMeans(algorithm='elkan', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "Purity = 0.7521827224166513\n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "Purity = 0.7528009828009828\n",
      "KMeans(algorithm='full', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "Purity = 0.7528009828009828\n",
      "KMeans(algorithm='elkan', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "Purity = 0.7528009828009828\n",
      "KMeans(algorithm='elkan', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "Purity = 0.7528009828009828\n"
     ]
    }
   ],
   "source": [
    "algos = ['auto', 'full', 'elkan']\n",
    "\n",
    "best_model = {}\n",
    "max_purity = 0\n",
    "for algo in algos:\n",
    "    for train_index, test_index in income_kf.split(income_X):\n",
    "        income_k_means = KMeans(n_clusters=2, algorithm=algo)\n",
    "        income_X_train, income_X_test = income_X.values[train_index], income_X.values[test_index]\n",
    "        income_Y_train, income_Y_test = income_Y.values[train_index], income_Y.values[test_index]\n",
    "        income_k_means.fit(income_X_train, income_Y_train)\n",
    "        purity_score = purity(income_k_means.predict(income_X_train), income_Y_train)\n",
    "        if (purity_score >= max_purity):\n",
    "            best_model = income_k_means\n",
    "            max_purity = purity_score\n",
    "    print(best_model)\n",
    "    print(\"Purity = \" + str(max_purity))\n",
    "print(best_model)\n",
    "print(\"Purity = \" + str(max_purity))\n",
    "\n",
    "income_full_X = income_X.append(income_test_X)\n",
    "income_full_Y = income_Y.append(income_test_Y)\n",
    "best_model = {}\n",
    "max_purity = 0\n",
    "for algo in algos:\n",
    "    for train_index, test_index in income_kf.split(income_full_X):\n",
    "        income_k_means = KMeans(n_clusters=2, algorithm=algo)\n",
    "        income_X_train, income_X_test = income_full_X.values[train_index], income_full_X.values[test_index]\n",
    "        income_Y_train, income_Y_test = income_full_Y.values[train_index], income_full_Y.values[test_index]\n",
    "        income_k_means.fit(income_X_train, income_Y_train)\n",
    "        purity_score = purity(income_k_means.predict(income_X_train), income_Y_train)\n",
    "        if (purity_score >= max_purity):\n",
    "            best_model = income_k_means\n",
    "            max_purity = purity_score\n",
    "    print(best_model)\n",
    "    print(\"Purity = \" + str(max_purity))\n",
    "print(best_model)\n",
    "print(\"Purity = \" + str(max_purity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Dari eksperimen di atas, didapatkan bahwa algoritma terbaik untuk model K-Means adalah:</p>\n",
    "\n",
    "<p><i>KMeans(algorithm='elkan', copy_x=True, init='k-means++', max_iter=300,\n",
    "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
    "    random_state=None, tol=0.0001, verbose=0)</i></p>\n",
    "    \n",
    "<p>untuk kedua dataset. Namun demikian, setelah melakukan eksperimen, didapatkan bahwa purity setiap algoritma ('auto'/'full'/'elkan') adalah sama.</p>\n",
    "\n",
    "<p>Pada eksperimen ini, dilakukan 10-fold cross validation untuk mendapatkan nilai purity terbaik.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
      "            connectivity=None, linkage='ward', memory=None, n_clusters=2,\n",
      "            pooling_func=<function mean at 0x7f7a7c082488>)\n",
      "Purity = 0.755\n",
      "AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
      "            connectivity=None, linkage='complete', memory=None,\n",
      "            n_clusters=2, pooling_func=<function mean at 0x7f7a7c082488>)\n",
      "Purity = 0.755\n",
      "AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
      "            connectivity=None, linkage='average', memory=None,\n",
      "            n_clusters=2, pooling_func=<function mean at 0x7f7a7c082488>)\n",
      "Purity = 0.755\n",
      "AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
      "            connectivity=None, linkage='average', memory=None,\n",
      "            n_clusters=2, pooling_func=<function mean at 0x7f7a7c082488>)\n",
      "Purity = 0.755\n"
     ]
    }
   ],
   "source": [
    "linkages = ['ward', 'complete', 'average']\n",
    "income_part_X = income_X.iloc[0:10000, :]\n",
    "income_part_Y = income_Y.iloc[0:10000]\n",
    "best_model = {}\n",
    "max_purity = 0\n",
    "for link in linkages:\n",
    "    income_agglomerative = AgglomerativeClustering(n_clusters=2, linkage=link)\n",
    "    income_agglomerative.fit(income_part_X)\n",
    "    purity_score = purity(income_agglomerative.fit_predict(income_part_X), income_part_Y)\n",
    "    if (purity_score >= max_purity):\n",
    "        best_model = income_agglomerative\n",
    "        max_purity = purity_score\n",
    "    print(best_model)\n",
    "    print(\"Purity = \" + str(max_purity))\n",
    "print(best_model)\n",
    "print(\"Purity = \" + str(max_purity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Dari eksperimen di atas, didapatkan bahwa linkage terbaik untuk model Agglomerative Clustering adalah:</p>\n",
    "\n",
    "<p><i>AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
    "            connectivity=None, linkage='ward', memory=None, n_clusters=2)</i></p>\n",
    "    \n",
    "<p>Namun demikian, setelah melakukan eksperimen, didapatkan bahwa purity setiap linkage ('ward'/'complete'/'average') adalah sama.</p>\n",
    "\n",
    "<p>Pada eksperimen ini, data dipotong menjadi 10.000 instances karena mesin yang digunakan tidak mampu menganalisis lebih dari 10000 instances. Mesin juga tidak dapat melakukan k-fold pada sekitar 30.000 instances. Karena itu, mesin juga tidak mampu melakukan analisis pada data training + data testing.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DBSCAN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN(algorithm='auto', eps=45, leaf_size=30, metric='euclidean',\n",
      "    metric_params=None, min_samples=4, n_jobs=1, p=None)\n",
      "Purity = 0.7935\n"
     ]
    }
   ],
   "source": [
    "income_part_X =  income_X.iloc[0:10000, :]\n",
    "income_part_Y = income_Y.iloc[0:10000]\n",
    "best_model = {}\n",
    "max_purity = 0\n",
    "\n",
    "best_eps = {}\n",
    "for eps in range(40, 50):\n",
    "    dbscan_model = DBSCAN(eps=45, min_samples=4).fit(income_part_X)\n",
    "    purity_score = purity(dbscan_model.fit_predict(income_part_X), income_part_Y)\n",
    "    if (purity_score > max_purity):\n",
    "        best_model = dbscan_model\n",
    "        max_purity = purity_score\n",
    "        best_eps = eps\n",
    "        \n",
    "print(best_model)\n",
    "print(\"Purity = \" + str(max_purity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>Dari eksperimen di atas, didapatkan bahwa epsilon terbaik untuk model DBSCAN adalah:</p>\n",
    "<p><i>DBSCAN(algorithm='auto', eps=45, leaf_size=30, metric='euclidean', metric_params=None, min_samples=4, n_jobs=1, p=None)</i></p>\n",
    "<p>Pada eksperimen ini, data dipotong menjadi 10.000 instances karena mesin yang digunakan tidak mampu menganalisis lebih dari 10000 instances. Mesin juga tidak dapat melakukan k-fold pada sekitar 30.000 instances. Karena itu, mesin juga tidak mampu melakukan analisis pada data training + data testing.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
